{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ravdess_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Long short-term memory LSTM"
      ],
      "metadata": {
        "id": "AS8hxs0DFPmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs are the most powerful and well known subset of Recurrent neural networks"
      ],
      "metadata": {
        "id": "pPFNg_twFfpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #linear algebra\n",
        "import pandas as pd #data processing,CSV file I/O (e.g. pd.read_csv)\n",
        "import os #to use operating system dependent functionality\n",
        "import librosa #importing librosa library so sound data can be converted to a spectogram (to extract speech features)\n",
        "import wave #read and write WAV files\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "ZIx74wGCFoph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bB8f63CEExs"
      },
      "outputs": [],
      "source": [
        "import keras #makes program easier to run\n",
        "from keras.utils import to_categorical #imports function for the labels\n",
        "from keras.models import Sequential #create layer-by-layer models\n",
        "from keras.layers import * #basic building blocks of neural network (all)\n",
        "from keras.optimizers import rmsprop #optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(wav_file_name): #This function extracts mfcc features and obtain the mean of each dimension\n",
        "    y, sr = librosa.load(wav_file_name)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n",
        "    \n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "ErklXffwGntl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### load radvess speech dataset #####\n",
        "radvess_speech_labels = [] # to save extracted label/file\n",
        "ravdess_speech_data = [] # to save extracted features/file\n",
        "subset_dirs_list = ['Actor_01', 'Actor_02', 'Actor_03','Actor_04', 'Actor_05', 'Actor_06','Actor_07', 'Actor_08']\n",
        "\n",
        "for dirname, dirs, filenames in os.walk('/kaggle/input/ravdess-emotional-speech-audio/'):\n",
        "    #dirs[:] = [d for d in dirs if d in subset_dirs_list] # you can remove it to train the model over the entire dataset \n",
        "    for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))\n",
        "        radvess_speech_labels.append(int(filename[7:8]) - 1) # the index 7 and 8 of the file name represent the emotion label\n",
        "        wav_file_name = os.path.join(dirname, filename)\n",
        "        ravdess_speech_data.append(extract_mfcc(wav_file_name)) # extract MFCC features/file\n",
        "        \n",
        "print(\"The Dataset Has Finished Loading.\")"
      ],
      "metadata": {
        "id": "6jeUW4_4G-Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the dataset for deep learning models"
      ],
      "metadata": {
        "id": "flnqUsNsEfij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### convert data and label to array\n",
        "ravdess_speech_data_array = np.asarray(ravdess_speech_data) # convert the input to an array\n",
        "ravdess_speech_label_array = np.array(radvess_speech_labels)\n",
        "ravdess_speech_label_array.shape # get tuple of array dimensions\n",
        "\n",
        "#### make categorical labels\n",
        "labels_categorical = to_categorical(ravdess_speech_label_array) # converts a class vector (integers) to binary class matrix\n",
        "ravdess_speech_data_array.shape\n",
        "labels_categorical.shape\n",
        "print(ravdess_speech_label_array.shape, ravdess_speech_data_array.shape, labels_categorical.shape)"
      ],
      "metadata": {
        "id": "zRUKEJKbEgEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training, validating, and testing sets\n",
        "number_of_samples = ravdess_speech_data_array.shape[0]\n",
        "training_samples = int(number_of_samples * 0.8)\n",
        "validation_samples = int(number_of_samples * 0.1)\n",
        "test_samples = int(number_of_samples * 0.1)"
      ],
      "metadata": {
        "id": "HPLLwaZHErXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "def create_model_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, return_sequences=False, input_shape=(40, 1)))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(32))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(8))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    # Configures the model for training\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Kv4tUp9hExLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train using LSTM model\n",
        "model_A = create_model_LSTM()\n",
        "history = model_A.fit(np.expand_dims(ravdess_speech_data_array[:training_samples],-1), labels_categorical[:training_samples], validation_data=(np.expand_dims(ravdess_speech_data_array[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs=200, shuffle=True)"
      ],
      "metadata": {
        "id": "nkBejtktE1Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### loss plots using LSTM model\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sdObQDigE4yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### accuracy plots using LSTM model\n",
        "plt.clf()                                                \n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'ro', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r54zHXaAE73l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### evaluate using model A\n",
        "model_A.evaluate(np.expand_dims(ravdess_speech_data_array[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])"
      ],
      "metadata": {
        "id": "xsg-8901FAAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saveing model\n",
        "model_A.save_weights(\"Model_LSTM.h5\")"
      ],
      "metadata": {
        "id": "xc0ImDr6FDb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vcoERuGgFN2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}