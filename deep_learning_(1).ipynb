{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "60JL6bRxRsY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np #linear algebra\n",
        "import pandas as pd #data processing,CSV file I/O (e.g. pd.read_csv)\n",
        "import os #to use operating system dependent functionality\n",
        "import librosa #importing librosa library so sound data can be converted to a spectogram (to extract speech features)\n",
        "from librosa import display\n",
        "import wave #read and write WAV files\n",
        "import glob \n",
        "import matplotlib.pyplot as plt \n",
        "% pylab inline\n"
      ],
      "metadata": {
        "id": "toLIwevwCo_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SCsXtLUa9gp",
        "outputId": "2780323e-d05b-4c5e-ff0f-d49d8dabb24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "id": "YFmWpvbHN-z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, sampling_rate = librosa.load('/content/Drive/Ravdess.zip/03-01-01-01-01-01-01.wav')"
      ],
      "metadata": {
        "id": "ZdaJt6TrON6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)"
      ],
      "metadata": {
        "id": "Zn3kBmudOU3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Ravdess'\n",
        "lst = []\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        file = file[6:8]\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue      "
      ],
      "metadata": {
        "id": "tehPCa4WPFt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "dRezeBzdPWC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "eq-Q87YIPadK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "metadata": {
        "id": "FISCp-vIR-xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape"
      ],
      "metadata": {
        "id": "NbTDlOFmRtdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Q-6hZyzdSFu5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This function trains the neural network.\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128, 5,padding='same',\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.rmsprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "metadata": {
        "id": "ZwCCMn5GSGdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "MbfhCaaFSNFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and fit our model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w3tUHWoFSQ8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/archivee/drive')"
      ],
      "metadata": {
        "id": "q-PiJFrHZqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
      ],
      "metadata": {
        "id": "-BYW1a-nSXK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Loss plotting\n",
        " plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fz7RlHfwSwwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Accuracy plotting\n",
        "plt.plot(cnnhistory.history['acc'])\n",
        "plt.plot(cnnhistory.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ubyn_iUAS3eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
        "save_dir = '/content/drive/My Drive/Ravdess_model'\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "metadata": {
        "id": "jgr3Vt0VS-jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reloading the model to test it\n",
        "loaded_model = keras.models.load_model('/content/drive/My Drive/Ravdess_model/Emotion_Voice_Detection_Model.h5')\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "C1QTuYnbTTV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the accuracy of the loaded model\n",
        "loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "KgPJDorIThtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "3wrFJlKm013A"
      }
    }
  ]
}